{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "849a9536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divece:  cuda\n",
      "The file does not exist\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    614\u001b[0m             sock = self.retry.call_with_retry(\n\u001b[1;32m--> 615\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             )\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\retry.py\u001b[0m in \u001b[0;36mcall_with_retry\u001b[1;34m(self, do, fail)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_supported_errors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\connection.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    614\u001b[0m             sock = self.retry.call_with_retry(\n\u001b[1;32m--> 615\u001b[1;33m                 \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m             )\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\connection.py\u001b[0m in \u001b[0;36m_connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"socket.getaddrinfo returned an empty list\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\connection.py\u001b[0m in \u001b[0;36m_connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    667\u001b[0m                 \u001b[1;31m# connect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19204/1999416704.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;31m# clear cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\flask_caching\\__init__.py\u001b[0m in \u001b[0;36mclear\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;34m\"\"\"Proxy function for internal cache object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\flask_caching\\backends\\rediscache.py\u001b[0m in \u001b[0;36mclear\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_prefix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_clients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_prefix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\commands\\core.py\u001b[0m in \u001b[0;36mkeys\u001b[1;34m(self, pattern, **kwargs)\u001b[0m\n\u001b[0;32m   1824\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minformation\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mredis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mcommands\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m         \"\"\"\n\u001b[1;32m-> 1826\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"KEYS\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m     def lmove(\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\client.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[0mpool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection_pool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m         \u001b[0mcommand_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpool\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\connection.py\u001b[0m in \u001b[0;36mget_connection\u001b[1;34m(self, command_name, *keys, **options)\u001b[0m\n\u001b[0;32m   1390\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m             \u001b[1;31m# ensure this connection is connected to Redis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m             \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m             \u001b[1;31m# connections that the pool provides should be ready to send\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m             \u001b[1;31m# a command. if not, the connection was either returned to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\conda\\envs\\tf_gpu\\lib\\site-packages\\redis\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Timeout connecting to server\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_error_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: Error 10061 connecting to localhost:6379. No connection could be made because the target machine actively refused it."
     ]
    }
   ],
   "source": [
    "from http.client import OK\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from utils import *\n",
    "from utils import _nms\n",
    "import json\n",
    "from flask import Flask, request, render_template, redirect, send_file\n",
    "from tensorflow.keras.models import load_model\n",
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision.ops import nms \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.draw import rectangle_perimeter\n",
    "from flask_caching import Cache\n",
    "from app import cache\n",
    "\n",
    "from models.HRCenterNet import HRCenterNet\n",
    "input_size = 512\n",
    "output_size = 128\n",
    "\n",
    "test_tx = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('divece: ', device)\n",
    "#model = load_model(MODEL_PATH)\n",
    "checkpoint = torch.load('models/HRCenterNet.pth.tar', map_location=\"cpu\")    \n",
    "    \n",
    "model = HRCenterNet()\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "# Initialize\n",
    "if os.path.exists(\"static/save/last.jpg\"):\n",
    "    os.remove(\"static/save/last.jpg\")\n",
    "else:\n",
    "    print(\"The file does not exist\")\n",
    "cache = Cache(config={'CACHE_TYPE': 'redis'})\n",
    "app = Flask(__name__)\n",
    "cache.init_app(app)\n",
    "\n",
    "# clear cache\n",
    "with app.app_context():\n",
    "    cache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353e8164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divece:  cuda\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision.ops import nms\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.draw import rectangle_perimeter\n",
    "from utils import *\n",
    "\n",
    "from models.HRCenterNet import HRCenterNet\n",
    "\n",
    "input_size = 512\n",
    "output_size = 128\n",
    "\n",
    "test_tx = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('divece: ', device)\n",
    "checkpoint = torch.load('models/HRCenterNet.pth.tar', map_location=\"cpu\")    \n",
    "model = HRCenterNet()\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "def _nms( img, predict, nms_score, iou_threshold):\n",
    "    \n",
    "    bbox = list()\n",
    "    score_list = list()\n",
    "    im_draw = np.asarray(torchvision.transforms.functional.resize(img, (img.size[1], img.size[0]))).copy()\n",
    "    \n",
    "    heatmap=predict.data.cpu().numpy()[0, 0, ...]\n",
    "    offset_y = predict.data.cpu().numpy()[0, 1, ...]\n",
    "    offset_x = predict.data.cpu().numpy()[0, 2, ...]\n",
    "    width_map = predict.data.cpu().numpy()[0, 3, ...]\n",
    "    height_map = predict.data.cpu().numpy()[0, 4, ...]\n",
    "    \n",
    "    \n",
    "    for j in np.where(heatmap.reshape(-1, 1) >= nms_score)[0]:\n",
    "\n",
    "        row = j // output_size \n",
    "        col = j - row*output_size\n",
    "        \n",
    "        bias_x = offset_x[row, col] * (img.size[1] / output_size)\n",
    "        bias_y = offset_y[row, col] * (img.size[0] / output_size)\n",
    "\n",
    "        width = width_map[row, col] * output_size * (img.size[1] / output_size)\n",
    "        height = height_map[row, col] * output_size * (img.size[0] / output_size)\n",
    "\n",
    "        score_list.append(heatmap[row, col])\n",
    "\n",
    "        row = row * (img.size[1] / output_size) + bias_y\n",
    "        col = col * (img.size[0] / output_size) + bias_x\n",
    "\n",
    "        top = row - width // 2\n",
    "        left = col - height // 2\n",
    "        bottom = row + width // 2\n",
    "        right = col + height // 2\n",
    "\n",
    "        start = (top, left)\n",
    "        end = (bottom, right)\n",
    "\n",
    "        bbox.append([top, left, bottom, right])\n",
    "        \n",
    "    _nms_index = torchvision.ops.nms(torch.FloatTensor(bbox), scores=torch.flatten(torch.FloatTensor(score_list)), iou_threshold=iou_threshold)\n",
    "    \n",
    "    for k in range(len(_nms_index)):\n",
    "    \n",
    "        top, left, bottom, right = bbox[_nms_index[k]]\n",
    "        \n",
    "        start = (top, left)\n",
    "        end = (bottom, right)\n",
    "        \n",
    "        rr, cc = rectangle_perimeter(start, end=end,shape=(img.size[1], img.size[0]))\n",
    "        \n",
    "        im_draw[rr, cc] = (255, 0, 0)\n",
    "        \n",
    "    return im_draw\n",
    "\n",
    "#print(model)\n",
    "image = Image.open('static/save/page01a.jpg').convert(\"RGB\")\n",
    "image_tensor = test_tx(image)\n",
    "image_tensor = image_tensor.unsqueeze_(0)\n",
    "inp = Variable(image_tensor)\n",
    "inp = inp.to(device, dtype=torch.float)\n",
    "\n",
    "predict = model(inp)\n",
    "out_img = _nms( image, predict, nms_score=0.3, iou_threshold=0.1)\n",
    "Image.fromarray(out_img).save('static/save/test.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bf719e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divece:  cuda\n",
      "Load checkpoint from models/HRCenterNet.pth.tar\n",
      "saving image to  test-1871/last.jpg\n",
      "saving image to  test-1871/page01a.jpg\n"
     ]
    }
   ],
   "source": [
    "%run - test.py --data_dir static/save/ --log_dir models/HRCenterNet.pth.tar  --output_dir test-1871/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
